{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HJ74Id-8MERq"
   },
   "outputs": [],
   "source": [
    "import pyvirtualdisplay\n",
    "import imageio \n",
    "import base64\n",
    "import IPython\n",
    "\n",
    "\n",
    "from acme import EnvironmentLoop\n",
    "from acme.tf import networks\n",
    "from acme.wrappers import gym_wrapper\n",
    "from acme import specs\n",
    "from acme.agents.tf import dqn\n",
    "from acme.utils.loggers.tf_summary import TFSummaryLogger\n",
    "import trfl\n",
    "\n",
    "import sonnet as snt\n",
    "import tensorflow as tf\n",
    "\n",
    "from utils import sonnet_resnet\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n",
    "# Set up a virtual display for rendering OpenAI gym environments.\n",
    "display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.gym_env import MinerEnv\n",
    "\n",
    "def display_video(frames, filename='temp.mp4'):\n",
    "  \"\"\"Save and display video.\"\"\"\n",
    "  # Write video\n",
    "  with imageio.get_writer(filename, fps=60) as video:\n",
    "    for frame in frames:\n",
    "      video.append_data(frame)\n",
    "  # Read video and display the video\n",
    "  video = open(filename, 'rb').read()\n",
    "  b64_video = base64.b64encode(video)\n",
    "  video_tag = ('<video  width=\"320\" height=\"240\" controls alt=\"test\" '\n",
    "               'src=\"data:video/mp4;base64,{0}\">').format(b64_video.decode())\n",
    "  return IPython.display.HTML(video_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym_wrapper.GymWrapper(MinerEnv())\n",
    "environment_spec = specs.make_environment_spec(env)\n",
    "\n",
    "base_net = snt.Sequential([\n",
    "    sonnet_resnet.ResNetTorso(num_output_hidden=(environment_spec.actions.num_values * 2, )),\n",
    "    networks.LayerNormMLP(layer_sizes=(environment_spec.actions.num_values,))\n",
    "])\n",
    "\n",
    "epsilon = tf.Variable(1., trainable=False)\n",
    "rl = tf.Variable(0.00025, trainable=False)\n",
    "\n",
    "policy_modules = [\n",
    "    base_net,\n",
    "    lambda q: trfl.epsilon_greedy(q, epsilon=epsilon).sample(),\n",
    "    lambda x: tf.cast(x, tf.int64)\n",
    "]\n",
    "\n",
    "policy_network = snt.Sequential(policy_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function _yield_value at 0x7ff3071be3a0> appears to be a generator function. It will not be converted by AutoGraph.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "agent = dqn.DQN(\n",
    "    environment_spec=environment_spec,\n",
    "    network=base_net,\n",
    "    policy_network=policy_network,\n",
    "    batch_size=10000,\n",
    "    # prefetch_size=8000,\n",
    "    target_update_period=10,\n",
    "    # samples_per_insert=8000,\n",
    "    # min_replay_size=5,\n",
    "    # max_replay_size=1000000,\n",
    "    importance_sampling_exponent=0.2,\n",
    "    priority_exponent=0.6,\n",
    "    n_step=4,\n",
    "#     epsilon=0.3,\n",
    "    learning_rate=rl,\n",
    "    discount=0.99,\n",
    "    logger=TFSummaryLogger('models/11_rl_001_e_3_nstep_4_bs10k_he/logs'),\n",
    "    checkpoint=True,\n",
    "    checkpoint_subpath='models/11_rl_001_e_3_nstep_4_bs10k_he',)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loop = EnvironmentLoop(env, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "steps = 10\n",
    "start_eps = 0.3\n",
    "end_eps = 0.3\n",
    "\n",
    "start_rl = 0.001\n",
    "end_rl = 0.001\n",
    "\n",
    "for step in range(steps):\n",
    "\n",
    "    epsilon.assign(start_eps - step * (start_eps - end_eps) / steps)\n",
    "    rl.assign(start_rl - step * (start_rl - end_rl) / steps)\n",
    "    \n",
    "    loop.run(num_episodes=int(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# epsilon.assign(0.1)\n",
    "# rl.assign(0.0001)\n",
    "# loop.run(num_episodes=int(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_env = gym_wrapper.GymWrapper(MinerEnv())\n",
    "import numpy as np\n",
    "frames = []\n",
    "num_steps = 100\n",
    "timestep = test_env.reset()\n",
    "\n",
    "while not timestep.last():\n",
    "    frames.append(test_env.environment.render(mode='rgb_array'))\n",
    "    action = agent.select_action(timestep.observation)\n",
    "    timestep = test_env.step(int(action))\n",
    "\n",
    "display_video(np.array(frames))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "VEEj3Qw60y73"
   ],
   "name": "Acme: Tutorial",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "acme38",
   "language": "python",
   "name": "acme38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}